{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of product reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to learn about langchain and came up with this little project to actually use the library for a somewhat realistic usecase.\n",
    "\n",
    "The goal of the project is to automatically extract useful insights from customer reviews on a single product.\n",
    "\n",
    "My learning goals are:\n",
    "- basic use of langchain\n",
    "  - structured output (simple tool use)\n",
    "  - extraction (of information from raw text)\n",
    "  - clustering\n",
    "- interactive plot for visualization\n",
    "- hosting of the plot (while maintaining interactivity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roadmap I came up with to achieve the above goals:\n",
    "\n",
    "1. Choose a product on amazon\n",
    "2. Gather some negative reviews (ideally >20)\n",
    "3. Extract critique points from each review\n",
    "4. Cluster all extracted critique points into broader categories\n",
    "5. Show the amount of critique points for each cluster over time\n",
    "6. Host the dynamic plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Choose a product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple enough. Open up amazon front page and click on the first item you see. I won't share what article this turned out to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the first roadblock. Amazon really doesn't want you to automatically scrape their pages (understandably). For any real business case one should definetly go through an official api. But for a quick toy project? I ended up opening the first 3 review pages manually in a browser (filtered for negative reviews), hit CTRL+S and went from there. Each page contains 10 reviews, so I ended up with 30 negative reviews buried deep inside a vast corpus of html. Fortunately html parsing is easily done with `beautifulsoup`.\n",
    "\n",
    "After parsing and some post-processing I ended up with this kind of structure for each review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '3,0 von 5 Sternen\\nToll, aber!',\n",
       " 'text': 'Meine Kinder lieben den Würfel, leider ist er vermutlich nicht dafür gebaut, wirklich lange und ständig verwendet zu werden. Die geklebte Folie löst sich nun ab.',\n",
       " 'rating': '3,0 von 5 Sternen',\n",
       " 'date': '25. Mai 2024'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "json.loads(Path('ReviewFetcher/raw_reviews/review_0.txt').read_text().replace(\"'\", '\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Extract critique points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fun part, I get to use LLMs. When I first tried this right when GPT-3 was available via api I had lots of trouble convincing it to output valid json. And only valid json, no \"certainly, here is ...\" prefix. Nowdays this seems to be solved, and elegantly at that. Basically you define a simple tool that's tailored to producing structured output. Defining the expected schema is done via pydantic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Review(BaseModel):\n",
    "    \"\"\"Collection of issues mentioned in a review\"\"\"\n",
    "    critique_points: list[str] = Field(description=\"List of issues mentioned in the review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember when your colleagues nag you to add proper comments to your code? Well, this time it's actually not optional at all. The docstring of the base class and the description of the field are both used by the model to determine what information to extract and how to match that with the fields in the class. The explanations in this example are rather short, but enough for my simple use case.\n",
    "\n",
    "Defining an llm with that expected output is then simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_openai_key\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_openai_key()\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0125\").with_structured_output(Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all that's left is a prompt which can be re-used for every one of the reviews. In langchain this is called a prompt template. Similar to f-strings you define a text with placeholders, which are populated later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_msg = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Extract all the issues mentioned in the review and return them as a list. Only extract concrete issues, not general sentiments. I.e. \"The battery life is too short\" is an issue, but \"I don't like the design\" is not.\n",
    "                                              Or \"not made to last long\" is not an issue, but \"(because) screws are loose\" is an issue.\n",
    "\n",
    "    Review:\n",
    "    {input}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together with langchains fancy chain-syntax gives us a callable object that takes a review as input, populates the prompt template, invokes the llm and returns the information structured in the `Review` class from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_msg | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review(critique_points=['Die geklebte Folie löst sich ab'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_review = \"Title: Toll, aber!\\nText: Meine Kinder lieben den Würfel, leider ist er vermutlich nicht dafür gebaut, wirklich lange und ständig verwendet zu werden. Die geklebte Folie löst sich nun ab.\\nRating: 3/5\\nDate: 2024-05-25\"\n",
    "\n",
    "chain.invoke({\"input\": example_review})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works like a charm. Now repeat that for every review, save the responses with the same (arbitrary) review id as the original ones to later match the creation date and this step is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Cluster customer issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a long list of customer issues, we want to form clusters of issues with similar meaning.\n",
    "\n",
    "The exact task I set was\n",
    "> Given the list of all issues, find clusters to group those issues\n",
    "\n",
    "In particular, I'm neither telling the system what the clusters are nor how many there are. I a real business case, this might be information that's already available.\n",
    "\n",
    "This step doesn't necessarily require an api call, you could just do it in the ChatGPT webinterface (where I tested it). However, since we're pretending this system would be run for thousands of articles this step should be automated via code. Also this gives me the opportunity to test a slightly more involved structured output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class IssuesWithId(BaseModel):\n",
    "    id: int = Field(..., description=\"ID of the issue\")\n",
    "    issues: list[str] = Field(..., description=\"list of issues from that critique that were associated with this cluster. Not all issues mentioned might belong to the same cluster\")\n",
    "    def __str__(self):\n",
    "        return f\"{self.id}: {self.issues}\"\n",
    "\n",
    "class ClusterRequest(BaseModel):\n",
    "    name: str = Field(..., description=\"Name of the cluster\")\n",
    "    description: str = Field(..., description=\"Brief description of what defines the cluster\")\n",
    "    ids: list[IssuesWithId] = Field(..., description=\"List of issues with their respective IDs\")\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}: {self.description}\\n{self.ids}\"\n",
    "\n",
    "class ClustersResponse(BaseModel):\n",
    "    clusters: list[ClusterRequest] = Field(..., description=\"List of clusters\")\n",
    "    def __str__(self):\n",
    "        return f\"{self.clusters}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the input being a list of `[id, [issues]]` pairs, the exptected output is a list of clusters. Each cluster should have:\n",
    "- name\n",
    "- brief description\n",
    "- list of all review ids with the corresponding issues that match the cluster\n",
    "\n",
    "In my brief tests I had to use `gpt-4o` for this task. The `gpt-3.5` model often only gave me a single cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\").with_structured_output(ClustersResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoking the llm with the list of all reviews, we get the clusters:\n",
    "- Durability Issues\n",
    "- Price Issues\n",
    "- Size Issues\n",
    "- Quality Issues\n",
    "- Usability Issues\n",
    "\n",
    "along with the list of reviews that fall under each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Visualization per cluster over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening the issues lists and merging back the creation date of the corresponding we end up with this dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster Name</th>\n",
       "      <th>Review ID</th>\n",
       "      <th>Issue</th>\n",
       "      <th>date</th>\n",
       "      <th>hover_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Durability Issues</td>\n",
       "      <td>0</td>\n",
       "      <td>Die geklebte Folie löst sich ab</td>\n",
       "      <td>2024-05-25</td>\n",
       "      <td>Die geklebte Folie löst sich ab (25.05.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Durability Issues</td>\n",
       "      <td>2</td>\n",
       "      <td>Es war nach wenigen Minuten kaputt</td>\n",
       "      <td>2024-05-05</td>\n",
       "      <td>Es war nach wenigen Minuten kaputt (05.05.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Durability Issues</td>\n",
       "      <td>4</td>\n",
       "      <td>am nächsten Tag schon gerissen</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>am nächsten Tag schon gerissen (10.04.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Durability Issues</td>\n",
       "      <td>8</td>\n",
       "      <td>nicht stabil</td>\n",
       "      <td>2024-03-21</td>\n",
       "      <td>nicht stabil (21.03.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Durability Issues</td>\n",
       "      <td>8</td>\n",
       "      <td>ziemlich schnell hinüber</td>\n",
       "      <td>2024-03-21</td>\n",
       "      <td>ziemlich schnell hinüber (21.03.24)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cluster Name  Review ID                               Issue  \\\n",
       "0  Durability Issues          0     Die geklebte Folie löst sich ab   \n",
       "1  Durability Issues          2  Es war nach wenigen Minuten kaputt   \n",
       "2  Durability Issues          4      am nächsten Tag schon gerissen   \n",
       "3  Durability Issues          8                        nicht stabil   \n",
       "4  Durability Issues          8            ziemlich schnell hinüber   \n",
       "\n",
       "         date                                     hover_text  \n",
       "0  2024-05-25     Die geklebte Folie löst sich ab (25.05.24)  \n",
       "1  2024-05-05  Es war nach wenigen Minuten kaputt (05.05.24)  \n",
       "2  2024-04-10      am nächsten Tag schon gerissen (10.04.24)  \n",
       "3  2024-03-21                        nicht stabil (21.03.24)  \n",
       "4  2024-03-21            ziemlich schnell hinüber (21.03.24)  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clusters_with_dates = pd.read_csv('clusters_with_dates.csv')\n",
    "clusters_with_dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the actual visiualization code... Well let's just say that was almost entirely done by ChatGpt. I'm quite confident in my matplotlib skills, but I've never done anything with an interactive plotting library. ChatGpt suggested using plotly, which I at least had heard before. The code looks readable and I can understand it, that's enough for me for now.\n",
    "\n",
    "If you want to dig in, feel free:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import locale\n",
    "\n",
    "# Set locale to English\n",
    "locale.setlocale(locale.LC_TIME, 'en_US.UTF-8')\n",
    "\n",
    "# Sample data\n",
    "data = pd.merge(issues, dates_df, on='Review ID')\n",
    "\n",
    "# Convert 'date' column to datetime if not already\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Resample to monthly frequency and count the number of issues\n",
    "monthly_issues = data.groupby(['Cluster Name', pd.Grouper(key='date', freq='ME')]).size().reset_index(name='Issue Count')\n",
    "\n",
    "# Create a string for the hover data combining issue descriptions\n",
    "data['hover_text'] = data['Issue'] + \" (\" + data['date'].dt.strftime('%d.%m.%y') + \")\"\n",
    "hover_text_df = data.groupby(['Cluster Name', pd.Grouper(key='date', freq='ME')])['hover_text'].apply(lambda x: '<br>'.join(x)).reset_index()\n",
    "\n",
    "# Merge hover_text back to monthly_issues\n",
    "monthly_issues = monthly_issues.merge(hover_text_df, on=['date', 'Cluster Name'], how='left')\n",
    "\n",
    "# Plot using plotly\n",
    "fig = px.bar(monthly_issues, x='date', y='Issue Count', color='Cluster Name', barmode='group',\n",
    "             custom_data=['hover_text'],\n",
    "             title='Monthly Number of New Issues for Each Cluster')\n",
    "\n",
    "# Update hover template to show issues only\n",
    "fig.update_traces(hovertemplate='%{customdata}')\n",
    "\n",
    "fig.update_layout(xaxis_title='Month', yaxis_title='Number of Issues',  width=1000,  # Set the width of the plot\n",
    "    bargap=0.1)   # Set the gap between bars (0 to 1, where 0 is no gap and 1 is full gap))\n",
    "\n",
    "fig.write_html(\"plot.html\")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <iframe src=\"plot.html\" style=\"width: 100%; height: 600px; border: none;\"></iframe>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
